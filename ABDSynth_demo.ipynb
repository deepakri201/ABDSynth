{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ABDSynth demo notebook**\n",
    "\n",
    "This notebook allows the user to test the ABDSynth pre-trained model on a sample patient from the AMOS MR dataset. \n",
    "\n",
    "Notes: \n",
    "- Make sure to create an appropriate virtual environment according to https://github.com/BBillot/SynthSeg\n",
    "- You will need sufficient GPU memory to run this notebook, ~40GB. \n",
    "\n",
    "Deepa Krishnaswamy and Cosmin Ciausu\n",
    "Brigham and Women's Hospital\n",
    "May 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't already, clone the SynthSeg repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SynthSeg'...\n",
      "remote: Enumerating objects: 2479, done.\u001b[K\n",
      "remote: Counting objects: 100% (683/683), done.\u001b[K\n",
      "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
      "remote: Total 2479 (delta 613), reused 538 (delta 538), pack-reused 1796 (from 1)\u001b[K\n",
      "Receiving objects: 100% (2479/2479), 120.57 MiB | 64.61 MiB/s, done.\n",
      "Resolving deltas: 100% (1614/1614), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/BBillot/SynthSeg.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nibabel as nib \n",
    "import numpy as np \n",
    "\n",
    "curr_path = os.getcwd()\n",
    "sys.path.insert(0, os.path.join(curr_path, 'SynthSeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from SynthSeg.predict import predict as synthseg_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we download the model weights from github release attachments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  151M  100  151M    0     0  57.4M      0  0:00:02  0:00:02 --:--:-- 72.8M\n"
     ]
    }
   ],
   "source": [
    "!curl -f -L -O https://github.com/deepakri201/ABDSynth/releases/download/v1.0.0/dice_100.h5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs \n",
    "model_weights_filename = os.path.join(curr_path, 'dice_100.h5')\n",
    "path_images = os.path.join(curr_path, 'data')\n",
    "path_images_filename = os.path.join(curr_path, 'data', 'amos_0540.nii.gz')\n",
    "labels_segmentation_npy_filename = os.path.join(curr_path, 'npy', 'synthseg_segmentation_labels.npy')\n",
    "# output folder \n",
    "path_segmentations = os.path.join(curr_path, 'output')\n",
    "path_segmentations_filename = os.path.join(curr_path, 'output', 'amos_0540_synthseg.nii.gz')\n",
    "\n",
    "assert(os.path.exists(model_weights_filename))\n",
    "assert(os.path.exists(path_images))\n",
    "assert(os.path.exists(path_images_filename))\n",
    "assert(os.path.exists(labels_segmentation_npy_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting 1/1\n"
     ]
    }
   ],
   "source": [
    "# predict \n",
    "synthseg_predict(path_images=path_images_filename,\n",
    "                path_segmentations=path_segmentations_filename,\n",
    "                path_model=model_weights_filename,\n",
    "                labels_segmentation=labels_segmentation_npy_filename,\n",
    "                target_res=1.5,\n",
    "                gradients=False,\n",
    "                flip=False,\n",
    "                sigma_smoothing=0,\n",
    "                keep_biggest_component=True,\n",
    "                n_levels = 5,\n",
    "                nb_conv_per_level = 2,\n",
    "                conv_size = 3,\n",
    "                unet_feat_count = 24,\n",
    "                activation = 'elu',\n",
    "                feat_multiplier = 2,\n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted segmentation has isotropic spacing of 1.5mm. So we need to resample it back to the original spacing of the volume. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use itkwidgets to overlay the segmentations on the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
